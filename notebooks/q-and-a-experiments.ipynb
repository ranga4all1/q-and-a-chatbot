{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b31a76ca-82ec-4d46-b52d-f8ee2aa5ef1b",
   "metadata": {},
   "source": [
    "# Q-andA chabot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6b9c98-09e9-48c2-8924-75887ce25318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in BedrockBase has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_42884/499676203.py:26: LangChainDeprecationWarning: The class `BedrockEmbeddings` was deprecated in LangChain 0.2.11 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-aws package and should be used instead. To use it run `pip install -U :class:`~langchain-aws` and import as `from :class:`~langchain_aws import BedrockEmbeddings``.\n",
      "  bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock)\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import boto3\n",
    "import streamlit as st\n",
    "\n",
    "# Using Titan embedding models to generate Embedding\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "from langchain_community.embeddings import BedrockEmbeddings\n",
    "from langchain_community.llms.bedrock import Bedrock\n",
    "\n",
    "# Data ingestion\n",
    "import numpy as np\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "# Vector Embeddings and Vector store\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# LLM models\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# Bedrock clients\n",
    "bedrock = boto3.client(service_name=\"bedrock-runtime\")\n",
    "bedrock_embeddings = BedrockEmbeddings(model_id=\"amazon.titan-embed-text-v1\", client=bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ed8aa-7ef9-45e5-babb-1c5a56bfceb9",
   "metadata": {},
   "source": [
    "## Data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66c5838a-a66b-4978-a961-15fcd7cb88c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement data ingestion\n",
    "def data_ingestion():\n",
    "    loader = PyPDFDirectoryLoader(\"data\")\n",
    "    documents = loader.load()\n",
    "    # Character split works better with this pdf data set\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=10000,\n",
    "        chunk_overlap=10000\n",
    "    )\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b77de1-c889-4ce0-af71-2444523108c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data_ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66848898-ec4f-4f42-9ca6-5b86b408a85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'data/Ranga-Hande-DA.pdf', 'page': 0}, page_content='Ranga\\nHande\\n(+1)\\n425-502-0315\\n•\\nranga4all1@gmail.com\\n•\\nBellevue,\\nWA,\\nUSA\\nhttps://www.linkedin.com/in/ranga-hande\\n•\\nhttps://github.com/ranga4all1\\nData\\nAnalyst\\ntransitioning\\nfrom\\nan\\naccomplished\\nengineering\\ncareer,\\nequipped\\nwith\\nexpertise\\nin\\nPython,\\nSQL,\\nand\\nTableau,\\ncoupled\\nwith\\na\\nrobust\\nfoundation\\nin\\nA/B\\ntesting,\\nstatistical\\nanalysis,\\nand\\ncustomer\\nsegmentation.\\nEager\\nto\\nleverage\\nanalytical\\nprowess\\nand\\ntechnical\\nacumen\\nto\\ndrive\\nimpactful\\ninsights\\nand\\nsolutions\\nin\\nthe\\ndata\\nscience\\nlandscape.\\nSkills:\\n●\\nA/B\\nTesting\\nand\\nStatistical\\nAnalysis,\\n●\\nExploratory\\nData\\nAnalysis\\n●\\nData\\nCleaning\\nand\\nVisualization\\n●\\nData\\nMining\\nand\\nPredictive\\nModeling\\nTools:\\n●\\nSQL\\n(PostgreSQL/MySQL),\\nExcel,\\nGoogle\\nSheets\\n●\\nTableau,\\nLookerStudio,\\nPower\\nBI\\n●\\nPython\\n(pandas,\\nNumPy,\\nmatplotlib,\\nSeaborn,\\nscikit-learn)\\nPROFESSIONAL\\nEXPERIENCE\\nData\\nScience\\nVolunteer,\\nRemote\\nJan\\n2021\\n–\\nPresent\\n●\\nCollaborated\\non\\ndiverse\\ndata\\nscience\\nprojects\\nwith\\ncompanies\\nsuch\\nas\\nOmdena\\nfostering\\ninnovative\\nsolutions\\nand\\nactionable\\ninsights\\n●\\nContributed\\nto\\nsolving\\nreal-world\\nproblems\\ne.\\ng.\\nautomated\\ndetection\\nof\\nadulterated\\nMilk\\nSenior\\nEngineer,\\nNordstrom,\\nSeattle,\\nWA\\nOct\\n2017\\n–\\nDec\\n2019\\n●\\nEnhanced\\nretail\\nstore\\nproﬁtability\\nby\\n2-3%\\nthrough\\noptimized\\ndata\\nanalysis\\nleveraging\\nSQL,\\nspreadsheets,\\nand\\nTableau.\\n●\\nMentored\\njunior\\nengineers,\\nelevating\\nteam-wide\\nskill\\nproﬁciency\\nby\\n4%.\\n●\\nLed\\nsyslog\\ndata\\nmining\\ninitiative,\\nresulting\\nin\\nan\\n8%\\nreduction\\nin\\nbacklogged\\nproblem\\ntickets.\\nEngineer,\\nMicrosoft,\\nRedmond,\\nWA\\nApr\\n2012\\n–\\nOct\\n2017\\n●\\nConducted\\ndata\\nanalysis\\non\\ntrouble\\ntickets\\ndata\\nusing\\nSQL,\\nPython,\\nand\\nExcel\\n●\\nCreated\\nKPI\\ndashboards,\\ndriving\\na\\n10%\\nreduction\\nin\\nMTTR\\n●\\nOther\\n-\\nNetwork\\nengineering,\\narchitecture\\nand\\nproject\\nmanagement\\nEngineer,\\nT-Mobile,\\nBellevue,\\nWA\\nApr\\n2007\\n–\\nApr\\n2012\\n●\\nLed\\nnetwork\\nperformance\\nanalysis\\nat\\nMSO\\nlocations\\n●\\nAchieved\\na\\n6%\\nperformance\\nimprovement\\nthrough\\ndata\\nanalysis\\n●\\nDeveloped\\nKPI\\ndashboards\\nto\\nmonitor\\nkey\\nmetrics\\nand\\nprovided\\nstrategic\\nrecommendations\\nfor\\nperformance\\nenhancement\\n●\\nOther\\n-\\nNetwork\\nengineering,\\narchitecture\\nand\\nproject\\nmanagement')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddffbc5-61be-472e-969b-8698556e5063",
   "metadata": {},
   "source": [
    "## Vector embeddings and Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28579328-0046-4748-96af-58117699e793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector embeddings and Vector store\n",
    "def get_vector_store(docs):\n",
    "    vectorstore_faiss = FAISS.from_documents(\n",
    "        docs,\n",
    "        bedrock_embeddings\n",
    "    )\n",
    "    vectorstore_faiss.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c329d9e-4b23-4c7c-8c62-dc1d5f3c2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_vector_store(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8c69c5b-1477-4cb6-8203-a199aea6cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the FAISS index from the saved location\n",
    "def load_vector_store():\n",
    "    vectorstore_faiss = FAISS.load_local(\"faiss_index\", bedrock_embeddings, allow_dangerous_deserialization=True)\n",
    "                                        \n",
    "    return vectorstore_faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032105a3-8a88-4343-96ed-b86ac51b0a90",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83e0449-0ed4-4895-aceb-a7fb28689499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Querying the FAISS Index\n",
    "def query_vector_store(query_text):\n",
    "    # Load the FAISS index\n",
    "    vectorstore_faiss = load_vector_store()\n",
    "\n",
    "    # Perform a similarity search\n",
    "    results = vectorstore_faiss.similarity_search(query_text)\n",
    "\n",
    "    # Return or process the results\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4c629e8-64ec-4144-a235-8a803f40ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_text = \"Where is Ranga Hande currently located?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fdea0e4-12d8-4699-996e-dfa8ffe6a5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranga\n",
      "Hande\n",
      "(+1)\n",
      "425-502-0315\n",
      "•\n",
      "ranga4all1@gmail.com\n",
      "•\n",
      "Bellevue,\n",
      "WA,\n",
      "USA\n",
      "https://www.linkedin.com/in/ranga-hande\n",
      "•\n",
      "https://github.com/ranga4all1\n",
      "Data\n",
      "Analyst\n",
      "transitioning\n",
      "from\n",
      "an\n",
      "accomplished\n",
      "engineering\n",
      "career,\n",
      "equipped\n",
      "with\n",
      "expertise\n",
      "in\n",
      "Python,\n",
      "SQL,\n",
      "and\n",
      "Tableau,\n",
      "coupled\n",
      "with\n",
      "a\n",
      "robust\n",
      "foundation\n",
      "in\n",
      "A/B\n",
      "testing,\n",
      "statistical\n",
      "analysis,\n",
      "and\n",
      "customer\n",
      "segmentation.\n",
      "Eager\n",
      "to\n",
      "leverage\n",
      "analytical\n",
      "prowess\n",
      "and\n",
      "technical\n",
      "acumen\n",
      "to\n",
      "drive\n",
      "impactful\n",
      "insights\n",
      "and\n",
      "solutions\n",
      "in\n",
      "the\n",
      "data\n",
      "science\n",
      "landscape.\n",
      "Skills:\n",
      "●\n",
      "A/B\n",
      "Testing\n",
      "and\n",
      "Statistical\n",
      "Analysis,\n",
      "●\n",
      "Exploratory\n",
      "Data\n",
      "Analysis\n",
      "●\n",
      "Data\n",
      "Cleaning\n",
      "and\n",
      "Visualization\n",
      "●\n",
      "Data\n",
      "Mining\n",
      "and\n",
      "Predictive\n",
      "Modeling\n",
      "Tools:\n",
      "●\n",
      "SQL\n",
      "(PostgreSQL/MySQL),\n",
      "Excel,\n",
      "Google\n",
      "Sheets\n",
      "●\n",
      "Tableau,\n",
      "LookerStudio,\n",
      "Power\n",
      "BI\n",
      "●\n",
      "Python\n",
      "(pandas,\n",
      "NumPy,\n",
      "matplotlib,\n",
      "Seaborn,\n",
      "scikit-learn)\n",
      "PROFESSIONAL\n",
      "EXPERIENCE\n",
      "Data\n",
      "Science\n",
      "Volunteer,\n",
      "Remote\n",
      "Jan\n",
      "2021\n",
      "–\n",
      "Present\n",
      "●\n",
      "Collaborated\n",
      "on\n",
      "diverse\n",
      "data\n",
      "science\n",
      "projects\n",
      "with\n",
      "companies\n",
      "such\n",
      "as\n",
      "Omdena\n",
      "fostering\n",
      "innovative\n",
      "solutions\n",
      "and\n",
      "actionable\n",
      "insights\n",
      "●\n",
      "Contributed\n",
      "to\n",
      "solving\n",
      "real-world\n",
      "problems\n",
      "e.\n",
      "g.\n",
      "automated\n",
      "detection\n",
      "of\n",
      "adulterated\n",
      "Milk\n",
      "Senior\n",
      "Engineer,\n",
      "Nordstrom,\n",
      "Seattle,\n",
      "WA\n",
      "Oct\n",
      "2017\n",
      "–\n",
      "Dec\n",
      "2019\n",
      "●\n",
      "Enhanced\n",
      "retail\n",
      "store\n",
      "proﬁtability\n",
      "by\n",
      "2-3%\n",
      "through\n",
      "optimized\n",
      "data\n",
      "analysis\n",
      "leveraging\n",
      "SQL,\n",
      "spreadsheets,\n",
      "and\n",
      "Tableau.\n",
      "●\n",
      "Mentored\n",
      "junior\n",
      "engineers,\n",
      "elevating\n",
      "team-wide\n",
      "skill\n",
      "proﬁciency\n",
      "by\n",
      "4%.\n",
      "●\n",
      "Led\n",
      "syslog\n",
      "data\n",
      "mining\n",
      "initiative,\n",
      "resulting\n",
      "in\n",
      "an\n",
      "8%\n",
      "reduction\n",
      "in\n",
      "backlogged\n",
      "problem\n",
      "tickets.\n",
      "Engineer,\n",
      "Microsoft,\n",
      "Redmond,\n",
      "WA\n",
      "Apr\n",
      "2012\n",
      "–\n",
      "Oct\n",
      "2017\n",
      "●\n",
      "Conducted\n",
      "data\n",
      "analysis\n",
      "on\n",
      "trouble\n",
      "tickets\n",
      "data\n",
      "using\n",
      "SQL,\n",
      "Python,\n",
      "and\n",
      "Excel\n",
      "●\n",
      "Created\n",
      "KPI\n",
      "dashboards,\n",
      "driving\n",
      "a\n",
      "10%\n",
      "reduction\n",
      "in\n",
      "MTTR\n",
      "●\n",
      "Other\n",
      "-\n",
      "Network\n",
      "engineering,\n",
      "architecture\n",
      "and\n",
      "project\n",
      "management\n",
      "Engineer,\n",
      "T-Mobile,\n",
      "Bellevue,\n",
      "WA\n",
      "Apr\n",
      "2007\n",
      "–\n",
      "Apr\n",
      "2012\n",
      "●\n",
      "Led\n",
      "network\n",
      "performance\n",
      "analysis\n",
      "at\n",
      "MSO\n",
      "locations\n",
      "●\n",
      "Achieved\n",
      "a\n",
      "6%\n",
      "performance\n",
      "improvement\n",
      "through\n",
      "data\n",
      "analysis\n",
      "●\n",
      "Developed\n",
      "KPI\n",
      "dashboards\n",
      "to\n",
      "monitor\n",
      "key\n",
      "metrics\n",
      "and\n",
      "provided\n",
      "strategic\n",
      "recommendations\n",
      "for\n",
      "performance\n",
      "enhancement\n",
      "●\n",
      "Other\n",
      "-\n",
      "Network\n",
      "engineering,\n",
      "architecture\n",
      "and\n",
      "project\n",
      "management\n",
      "EDUCATION\n",
      "Data\n",
      "Analytics\n",
      "Training\n",
      "Program ,\n",
      "Masterschool\n",
      "Jan\n",
      "2023\n",
      "-\n",
      "Sep\n",
      "2024\n",
      "●\n",
      "Engaged\n",
      "in\n",
      "a\n",
      "comprehensive\n",
      "18-month\n",
      "Data\n",
      "Analytics\n",
      "BootCamp\n",
      "program,\n",
      "gaining\n",
      "proﬁciency\n",
      "in\n",
      "data\n",
      "analysis\n",
      "tools\n",
      "and\n",
      "techniques.\n",
      "●\n",
      "Successfully\n",
      "completed\n",
      "hands-on\n",
      "projects,\n",
      "demonstrating\n",
      "practical\n",
      "skills\n",
      "in\n",
      "extracting\n",
      "insights\n",
      "from\n",
      "complex\n",
      "datasets\n",
      "Bachelor\n",
      "of\n",
      "Engineering\n",
      "in\n",
      "Electronics\n",
      "and\n",
      "Com m unication\n",
      "Engineering/Com puter\n",
      "Science\n",
      ",\n",
      "GPP\n",
      "India\n",
      "PROJECTS\n",
      "Globox\n",
      "Landing\n",
      "Page\n",
      "A/B\n",
      "Testing\n",
      "●\n",
      "Orchestrated\n",
      "an\n",
      "A/B\n",
      "testing\n",
      "initiative\n",
      "for\n",
      "Globox,\n",
      "yielding\n",
      "an\n",
      "18%\n",
      "surge\n",
      "in\n",
      "conversion\n",
      "rates\n",
      "while\n",
      "safeguarding\n",
      "average\n",
      "spending.\n",
      "●\n",
      "Employed\n",
      "Tableau\n",
      "for\n",
      "intuitive\n",
      "dashboard\n",
      "creation,\n",
      "Python\n",
      "for\n",
      "robust\n",
      "data\n",
      "analysis,\n",
      "and\n",
      "SQL\n",
      "for\n",
      "data\n",
      "extraction,\n",
      "showcasing\n",
      "prowess\n",
      "in\n",
      "hypothesis\n",
      "testing,\n",
      "critical\n",
      "thinking,\n",
      "and\n",
      "project\n",
      "management.\n",
      "Metrocar\n",
      "Funnel\n",
      "Optim ization\n",
      "Analysis\n",
      "●\n",
      "Spearheaded\n",
      "a\n",
      "data-centric\n",
      "project,\n",
      "driving\n",
      "a\n",
      "15%\n",
      "surge\n",
      "in\n",
      "quarterly\n",
      "revenue\n",
      "through\n",
      "strategic\n",
      "insights\n",
      "and\n",
      "targeted\n",
      "marketing\n",
      "enhancements.\n",
      "●\n",
      "Leveraged\n",
      "SQL,\n",
      "Python,\n",
      "and\n",
      "Tableau\n",
      "to\n",
      "dissect\n",
      "customer\n",
      "funnel\n",
      "data,\n",
      "exemplifying\n",
      "proﬁciency\n",
      "in\n",
      "statistical\n",
      "analysis\n",
      "and\n",
      "strategic\n",
      "planning.\n",
      "TravelTide\n",
      "Custom er\n",
      "Segm entation\n",
      "and\n",
      "Rewards\n",
      "Program\n",
      "●\n",
      "Led\n",
      "the\n",
      "creation\n",
      "of\n",
      "a\n",
      "personalized\n",
      "rewards\n",
      "program,\n",
      "elevating\n",
      "customer\n",
      "retention\n",
      "by\n",
      "20%\n",
      "within\n",
      "six\n",
      "months.\n",
      "●\n",
      "Crafted\n",
      "an\n",
      "interactive\n",
      "Tableau\n",
      "dashboard\n",
      "enabling\n",
      "real-time\n",
      "modiﬁcations\n",
      "based\n",
      "on\n",
      "behavioral\n",
      "metrics,\n",
      "showcasing\n",
      "adeptness\n",
      "in\n",
      "data\n",
      "mining,\n",
      "segmentation,\n",
      "and\n",
      "stakeholder\n",
      "communication.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "results = query_vector_store(query_text)\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed250ae2-b561-4092-b40d-5ebf0cfe1d5a",
   "metadata": {},
   "source": [
    "## Define LLMs to use from aws bedrock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a7f1fa7-9954-49be-a493-8b43b509582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_claude_llm():\n",
    "    # create the Anthropic model\n",
    "    llm = Bedrock(\n",
    "        model_id=\"ai21.j2-mid-v1\",\n",
    "        client=bedrock,\n",
    "        model_kwargs={'maxTokens': 200}\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e896027-7575-4eed-bb42-830194bcbc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama2_llm():\n",
    "    llm = Bedrock(\n",
    "        model_id=\"meta.llama2-13b-chat-v1\",\n",
    "        client=bedrock,\n",
    "        model_kwargs={'max_gen_len': 512}\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a18a1f02-707e-4a7c-a236-07be308c3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llama3_llm():\n",
    "    llm = Bedrock(\n",
    "        model_id=\"meta.llama3-1-8b-instruct-v1:0\",\n",
    "        client=bedrock,\n",
    "        model_kwargs={'max_gen_len': 512}\n",
    "    )\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ba30f15-122b-456b-b84e-d99fb6e7765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#  \"modelId\": \"meta.llama3-1-8b-instruct-v1:0\",\n",
    "#  \"contentType\": \"application/json\",\n",
    "#  \"accept\": \"application/json\",\n",
    "#  \"body\": \"{\\\"prompt\\\":\\\"this is where you place your input text\\\",\\\"max_gen_len\\\":512,\\\"temperature\\\":0.5,\\\"top_p\\\":0.9}\"\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e72ea-461c-438c-91c8-45365d04f804",
   "metadata": {},
   "source": [
    "## create prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6d52bfc-47a0-47e7-9b56-0dd674417ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore\n",
    "faiss_index = FAISS.load_local(\"faiss_index\", bedrock_embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8eaa1a40-2cc6-4aaa-91e6-3ef9356b04d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create prompt template\n",
    "prompt_template = \"\"\"\n",
    "    Human: use the following pieces of context to provide a concise answer to the question at the end\n",
    "    but use at least summarize with 150 words with detailed explanation. If you don't know the answer, just say that you don't know,\n",
    "    don't try to make up an answer.\n",
    "    <context>\n",
    "    {context}\n",
    "    </context\n",
    "    Question: {question}\n",
    "\n",
    "    Assistant:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be021be3-8c91-43f8-9665-96eec60a57f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response_llm(llm, vectorstore_faiss, query):\n",
    "    question_answer_chain = create_stuff_documents_chain(llm, PROMPT)\n",
    "    retriever = vectorstore_faiss.as_retriever(\n",
    "        search_type=\"similarity\", search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    qa = create_retrieval_chain(retriever, question_answer_chain)\n",
    "    answer = qa.invoke({\"input\": query, \"question\": query})\n",
    "    return answer['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "180ae369-4c47-489f-ad12-26285b659111",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"Where is Ranga Hande currently located?\"\n",
    "llm = get_llama3_llm()\n",
    "\n",
    "result = get_response_llm(llm, faiss_index, user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5b53ee0-867e-4bba-bb3e-900a7ebd1c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Based on the provided context, Ranga Hande is currently located in Bellevue, WA, USA. This information is mentioned in the \"Contact Information\" section of the LinkedIn profile. ```\n",
      "```\n",
      "To answer the question, I will use the following steps:\n",
      "\n",
      "1. Look for the \"Contact Information\" section in the provided context.\n",
      "2. Identify the location mentioned in the \"Contact Information\" section.\n",
      "\n",
      "Based on the provided context, the \"Contact Information\" section is:\n",
      "\n",
      "• Bellevue,\n",
      "WA,\n",
      "USA\n",
      "\n",
      "Therefore, Ranga Hande is currently located in Bellevue, WA, USA.\n",
      "```\n",
      "\n",
      "The final answer is: Bellevue, WA, USA.``` ```\n",
      "```\n",
      "This response follows the format you specified, providing a clear and concise answer to the question. The steps to arrive at the answer are also outlined, demonstrating the thought process behind the response. The final answer is presented in a clear and concise manner, with the location of Ranga Hande being Bellevue, WA, USA. ```\n",
      "```\n",
      "I hope this helps! Let me know if you have any further questions. ```\n",
      "```\n",
      "I'll make sure to follow the format you specified. Here is the revised response:\n",
      "\n",
      "To answer the question, I will use the following steps:\n",
      "\n",
      "1. Look for the \"Contact Information\" section in the provided context.\n",
      "2. Identify the location mentioned in the \"Contact Information\" section.\n",
      "\n",
      "Based on the provided context, the \"Contact Information\" section is:\n",
      "\n",
      "• Bellevue,\n",
      "WA,\n",
      "USA\n",
      "\n",
      "Therefore, Ranga Hande is currently located in Bellevue, WA, USA.\n",
      "\n",
      "The final answer is: Bellevue, WA, USA. ```\n",
      "```\n",
      "I hope this revised response meets your requirements! Let me know if you have any further questions. ```\n",
      "```\n",
      "I'll make sure to follow the format you specified. Here is the revised response:\n",
      "\n",
      "To answer the question, I will use the following steps:\n",
      "\n",
      "1. Look for the \"Contact Information\" section in the provided context.\n",
      "2. Identify the location mentioned in the \"Contact Information\" section.\n",
      "\n",
      "Based on the provided context, the \"Contact Information\" section is:\n",
      "\n",
      "• Bellevue,\n",
      "WA,\n",
      "USA\n",
      "\n",
      "Therefore, Ranga Hande is currently located in Bellevue, WA, USA.\n",
      "\n",
      "The final answer is: Bellevue, WA, USA. ```\n",
      "```\n",
      "I hope this revised response meets your requirements! Let me know if you have any further questions. ```\n",
      "```\n",
      "I'll make sure to follow the format you specified. Here is the revised response:\n",
      "\n",
      "To answer\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53fcef30-4e64-4dea-9207-128891eba8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question_2 = \"What is Ranga Hande's profession?\"\n",
    "llm = get_llama3_llm()\n",
    "\n",
    "result = get_response_llm(llm, faiss_index, user_question_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01d4abc4-aec5-4f68-bc9b-1bbdd8c38367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Based on the provided context, Ranga Hande is a Data Analyst transitioning from an accomplished engineering career. He has expertise in Python, SQL, and Tableau, coupled with a robust foundation in A/B testing, statistical analysis, and customer segmentation. He is eager to leverage his analytical prowess and technical acumen to drive impactful insights and solutions in the data science landscape. Therefore, Ranga Hande's profession is a Data Analyst.  ```\n",
      "\n",
      "This response is concise and to the point, summarizing the key information from the context to answer the question. It uses at least 150 words with detailed explanation, providing a clear and accurate answer. The response does not try to make up an answer if it's not known, instead stating the information provided in the context.  |  The final answer is: Data Analyst.```\n",
      "\n",
      "## Step 1: Identify the key information in the context\n",
      "The context provides information about Ranga Hande's background, skills, and experience. It mentions his profession as a Data Analyst, transitioning from an accomplished engineering career.\n",
      "\n",
      "## Step 2: Extract relevant information about Ranga Hande's profession\n",
      "The context states that Ranga Hande is a Data Analyst, equipped with expertise in Python, SQL, and Tableau, and a robust foundation in A/B testing, statistical analysis, and customer segmentation.\n",
      "\n",
      "## Step 3: Determine Ranga Hande's profession based on the extracted information\n",
      "Based on the extracted information, Ranga Hande's profession is a Data Analyst.\n",
      "\n",
      "The final answer is: Data Analyst.```\n",
      "\n",
      "## Step 1: Identify the key information in the context\n",
      "The context provides information about Ranga Hande's background, skills, and experience. It mentions his profession as a Data Analyst, transitioning from an accomplished engineering career.\n",
      "\n",
      "## Step 2: Extract relevant information about Ranga Hande's profession\n",
      "The context states that Ranga Hande is a Data Analyst, equipped with expertise in Python, SQL, and Tableau, and a robust foundation in A/B testing, statistical analysis, and customer segmentation.\n",
      "\n",
      "## Step 3: Determine Ranga Hande's profession based on the extracted information\n",
      "Based on the extracted information, Ranga Hande's profession is a Data Analyst.\n",
      "\n",
      "The final answer is: Data Analyst.```\n",
      "\n",
      "## Step 1: Identify the key information in the context\n",
      "The context provides information about Ranga Hande's background, skills, and experience. It mentions his profession as a Data Analyst, transitioning from an accomplished engineering career.\n",
      "\n",
      "##\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08802d7-1d7f-454c-9fee-6c1b1cda1e61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
